{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83c\udfdb\ufe0f Financial ML Core: The Foundation","text":"<p>\"To push innovation forward, one must first master the foundations that got us here.\"</p> <p> </p> <p><code>finml-core</code> is an institutional-grade framework engineered from first principles to address the inherent uncertainty and structural complexity of financial time series. This library was born from the necessity to move beyond \"black-box\" API calls, providing a transparent and mathematically rigorous system that respects the unique statistical nature of market data.</p> <p>Rather than offering a collection of standard tools, <code>finml-core</code> provides a governed pipeline designed to prevent the most common pitfalls in Quantitative Finance\u2014such as look-ahead bias, information leakage, and the misapplication of standard cross-validation to non-IID data.</p> <p><code>finml-core</code> is a high-performance Python library designed for quantitative researchers and financial engineers. It implements rigorous methodologies proposed by Marcos L\u00f3pez de Prado in \"Advances in Financial Machine Learning\", ensuring that ML models for trading are free from common pitfalls like look-ahead bias and serial correlation leakage.</p>"},{"location":"#the-philosophy-of-financial-data-geometry","title":"\ud83d\udcd0 The Philosophy of Financial Data Geometry","text":"<p>In Quantitative Finance, the data structure is not just a container, it is a Coordinate System. Most generic machine learning frameworks fail because they treat financial series as flat tables, ignoring the relationship between time and specific assets. </p> <p><code>finml-core</code> enforces a strict 3-dimensional perspective\u2014Time \u00d7 Asset \u00d7 Feature\u2014through its mandatory MultiIndex Architecture.</p>"},{"location":"#why-date-ticker-is-non-negotiable","title":"Why [Date, Ticker] is Non-Negotiable","text":"<p>Financial time series are characterized by cross-sectional dependence and heterogeneous scales. By enforcing a <code>pd.MultiIndex</code> with <code>Date</code> and <code>Ticker</code> levels as the primary index, the framework achieves three critical objectives:</p> <ol> <li>Group-Wise Vectorization: Statistical operations (like volatility estimation or RSI) are calculated per asset in a vectorized manner. This ensures that a high-volatility ticker (like TSLA) never influences the normalization or feature scaling of a low-volatility one (like KO).</li> <li>Temporal Alignment: It ensures that during the Labeling Process, the \"Vertical Barrier\" (time-limit) is synchronized across the entire universe, even when dealing with assets that have different trading lifespans or missing bars.</li> <li>Prevention of Cross-Asset Leakage: By maintaining the asset identity at the index level, the Purging and Embargo mechanisms can precisely identify which specific observations must be removed without destroying the integrity of the rest of the universe.</li> </ol> <pre><code># The finml-core Standard for Data Integrity\n# High-level example of index setting:\ndf.index = pd.MultiIndex.from_tuples(tuples, names=['Date', 'Ticker'])\n</code></pre>"},{"location":"#core-engines-architectural-modules","title":"\u2699\ufe0f Core Engines &amp; Architectural Modules","text":"<p>The framework is organized into specialized engines, each designed to solve a specific challenge in the Financial ML pipeline. While they can be used independently, they are seamlessly orchestrated by the DatasetGenerator.</p>"},{"location":"#1-the-data-factory-architecture-datasetgenerator","title":"1. The Data Factory Architecture <code>DatasetGenerator</code>","text":"<p>The central nervous system of the library, abstracting the complexity of the entire pipeline into a unified interface.</p> <ul> <li>Dual-Mode Operation: Supports Provider Mode for automated fetching via integrated APIs (e.g., <code>yfinance</code>) and Custom Mode for ingesting user-provided DataFrames.</li> <li>Validation &amp; Integrity: Acts as a final gatekeeper, validating MultiIndex geometry and ensuring that features and labels are perfectly synchronized in time before model ingestion.</li> </ul>"},{"location":"#2-market-data-loader-marketdataloader","title":"2. Market Data Loader <code>MarketDataLoader</code>","text":"<p>The abstraction layer for rigorous data acquisition.</p> <ul> <li>Unified Schema: Translates heterogeneous data from various providers into a consistent internal format, eliminating \"Garbage In, Garbage Out\" at the source.</li> <li>Market Context: Integrated with market calendars to handle session gaps and holidays, ensuring the dataset reflects actual trading reality.</li> </ul>"},{"location":"#3-the-sanitization-engine-datacleaner","title":"3. The Sanitization Engine <code>DataCleaner</code>","text":"<p>Financial data is noisy and prone to leakage. This engine enforces a Strict Sanitization Protocol.</p> <ul> <li>Bidirectional Trimming: Automatically manages the \"warm-up\" period required for technical indicators and the \"look-ahead\" horizon required for future labels.</li> <li>Arrow of Time Integrity: Implements conservative forward-filling to handle liquidity gaps without introducing future information.</li> </ul>"},{"location":"#4-feature-engineering-featuregenerator","title":"4. Feature Engineering <code>FeatureGenerator</code>","text":"<p>Moves beyond simple technical analysis to create Statistically Sound Features.</p> <ul> <li>Multi-Lag Expansion: Automatically generates temporal sequences (lags) for every feature to capture market memory and autocorrelation.</li> <li>Relative Intelligence: Enables features to be calculated relative to a benchmark (e.g., an ETF), isolating idiosyncratic asset performance from broader market noise.</li> </ul>"},{"location":"#5-structural-labeling-triplebarrierlabeling","title":"5. Structural Labeling <code>TripleBarrierLabeling</code>","text":"<p>A path-dependent labeling engine that respects the reality of institutional risk management.</p> <ul> <li>Dynamic Boundaries: Uses realized volatility to set adaptive take-profit and stop-loss barriers.</li> <li>Holding Constraints: Implements vertical barriers (time-limits) to account for the cost of capital and opportunity costs.</li> </ul>"},{"location":"#6-model-selection-purgedkfold","title":"6. Model Selection <code>PurgedKFold</code>","text":"<p>Our safeguard against the \"Overfitting Trap\" in non-IID financial data.</p> <ul> <li>Leakage Prevention: Implements Purging to remove training observations whose labels overlap with the test set's timeframe.</li> <li>Memory Embargo: Applies a Quarantine Zone (Embargo) after the test set to neutralize the effects of slow-decaying serial correlation.</li> </ul>"},{"location":"#getting-started","title":"\ud83d\ude80 Getting Started","text":"<p>To ensure a clean and reproducible environment, follow these steps:</p>"},{"location":"#1-setup-environment","title":"1. Setup Environment","text":"<pre><code># Create a virtual environment\n# Windows\npython -m venv venv\n# MacOS/Linux\npython3 -m venv venv\n\n# Activate it\n# Windows\nvenv\\Scripts\\activae\n# MacOS/Linux\nsource venv/bin/Activate\n</code></pre>"},{"location":"#2-installation","title":"2. Installation","text":"<p>First, install the framework directly from the source. This will automatically trigger the installation of core dependencies defined in <code>pyproject.toml</code>:</p> <pre><code># Intall financial-ml-core library\n# Windows\npython -m pip install git+https://github.com/PPuertos/financial-ml-core.git\n# MacOS/Linux\npython3 -m pip install git+https://github.com/PPuertos/financial-ml-core.git\n</code></pre> \ud83d\udee0\ufe0f Are you a developer or planning to collaborate?  If you want to contribute to the project, run tests, or modify the source code, install the full development requirements to ensure you have all necessary tooling (like pytest and setuptools):  <pre><code># 1. Clone the repository\ngit clone https://github.com/PPuertos/financial-ml-core.git\ncd financial-ml-core\n\n# 2. Install in editable mode with development dependencies\n# Windows\npython -m pip install -e \".[dev]\"\n\n# MacOS/Linux\npython3 -m pip install -e \".[dev]\"\n</code></pre>"},{"location":"#usage-example-basic-financial-ml-pipeline","title":"\ud83e\uddea Usage Example: Basic Financial ML Pipeline","text":"<p>The following example demonstrates the complete workflow: from automated Multi-Asset Ingestion and Feature Engineering (including temporal lags) to Triple Barrier Labeling and rigorous Sanitization. The result is a production-ready dataset, free from look-ahead bias and numerical instability.</p> <p>This library provides the essential Purged Cross-Validation engines required to tune any Scikit-Learn model without falling into the \"overfitting trap\" caused by serial correlation, ensuring that your model's performance is statistically grounded.</p>"},{"location":"#1-orchestrating-the-data-factory","title":"1. Orchestrating the Data Factory","text":"<p>The <code>DatasetGenerator</code> is the core orchestrator that handles ingestion, sanitization, feature engineering, and labeling in a single synchronized flow.</p>"},{"location":"#automated-ingestion","title":"Automated Ingestion","text":"<p>In its simplest form, you only need to specify your tickers and the data source (from supported <code>PROVIDERS</code>). The framework will use institutional-grade defaults for feature engineering and labeling.</p> <pre><code># --- AUTOMATED MODE ---\nfrom finml_core.pipelines.data_factory import DatasetGenerator\n\n# 1. Input `data_source` parameter refering to the provider\ngenerator = DatasetGenerator(data_source='yfinance')\n\n# 2. Execute the pipeline\n# Automatically handles Ingestion, Sanitization, Features, and Labeling\nX, y = generator.run(\n    tickers=['AAPL', 'MSFT', 'GOOGL'],\n    etf_reference='^GSPC',\n    start_date='2018-01-01'\n)\n</code></pre> \ud83d\udcc2 Advanced: Using your own Custom Dataset  If you already have a dataset (e.g., from a local CSV or database), you can inject it directly. The only requirement is that your DataFrame must follow the MultiIndex [Date, Ticker] geometry.  <pre><code># --- CUSTOM MODE ---\nfrom finml_core.pipelines.data_factory import DatasetGenerator\n\n# Assume 'my_df' is a MultiIndex (Date, Ticker) DataFrame with OHLCV columns\n\n# Specifying 'my_df' dataset structure\ncustom_provider = {\n    'col_map': {\n        'open': 'Open', 'high': 'High', 'low': 'Low',\n        'close': 'Close', 'volume': 'Volume'\n    },\n    'ticker_level': 'Ticker',\n    'date_level': 'Date'\n}\n\ngenerator = DatasetGenerator(\n    custom_provider=custom_provider\n)\n\n# Pass your DataFrame directly to the run method\nX, y = generator.run(df_input=my_df)\n</code></pre>"},{"location":"#2-statistical-split-purging-embargo","title":"2. Statistical Split (Purging &amp; Embargo)","text":"<p>Standard random splits or naive chronological splits are insufficient in finance. Because our labels (via TBM) have a time duration (from \\(t_0\\) to \\(t_1\\)), training and testing observations can overlap, causing information leakage. </p> <p>We use <code>purged_train_test_split</code> to execute a rigorous separation:</p> <ul> <li>Purging: Removes training samples whose evaluation period overlaps with the test set.</li> <li>Embargo: Adds a \"quarantine\" buffer immediately after the test set to neutralize any residual serial correlation (market memory).</li> </ul> <pre><code>from finml_core.model_selection.split import purged_train_test_split\n\n# Extracting t1 (label end dates for Purged CV)\nanalysis_data = generator.analysis_data\nt1 = analysis_data['t1']\n\n# Split Data into Train &amp; Test (Purged &amp; Embargoed)\nX_train, y_train, X_test, y_test = purged_train_test_split(\n    X, y, t1, \n    date_level='Date',\n    test_size=.2\n)\n\nprint(f\"\\nTrain size: {X_train.shape} | Test size: {X_test.shape}\")\nprint(f\"Purging + Embargo dates = {X.shape[0] - X_train.shape[0] - X_test.shape[0]}\")\n</code></pre>"},{"location":"#3-leakage-free-validation-purged-k-fold","title":"3. Leakage-Free Validation (Purged K-Fold)","text":"<p>Standard Cross-Validation assumes that observations are independent and identically distributed (I.I.D.). In finance, this assumption is false. To evaluate a model or prepare for hyperparameter tuning without \"lying\" to ourselves, we implement <code>PurgedKFold</code>. </p> <p>This cross-validator acts as a drop-in replacement for Scikit-Learn's K-Fold, ensuring that every training fold is mathematically isolated from the validation set by respecting the temporal overlap of labels.</p> <pre><code>from finml_core.model_selection.split import PurgedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\n\n# 1. Create the Purged Cross-Validator using the training 't1' dates.\n# This ensures that each fold is separated by purging and an embargo period.\npurged_cv = PurgedKFold(\n    n_splits=5,\n    t1=analysis_data.loc[X_train.index, 't1'],\n    date_level='Date',\n    pct_embargo=0.01\n)\n\n# 2. Define your model (e.g., RandomForest)\nrf_model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n\n# 3. Compute scores using the Purged CV engine.\n# This setup is also compatible with sklearn.model_selection.GridSearchCV.\nscores = cross_val_score(\n    rf_model, \n    X_train, \n    y_train, \n    cv=purged_cv.split(X_train, y_train), \n    scoring='accuracy',\n    n_jobs=-1\n)\n\nprint(f\"Purged CV Accuracy: {np.mean(scores):.2%} (+/- {np.std(scores):.4f})\")\n</code></pre>"},{"location":"#license-ethical-note","title":"\u2696\ufe0f License &amp; Ethical Note","text":"<p>This project is licensed under the MIT License. <code>finml-core</code> is an open-source contribution to the quantitative finance community. It is designed for research and educational purposes. Always remember: Backtesting is not forecasting, and past performance does not guarantee future results.</p>"},{"location":"#why-finml-core","title":"\ud83c\udfdb\ufe0f Why <code>finml-core</code>?","text":"<ul> <li>Integrity First: Every line of code is written to prevent data leakage, the #1 killer of financial ML models.</li> <li>Built for Production: Unlike fragmented notebooks, this is a structured library with modular engines.</li> <li>Theoretical Rigor: We don't just \"fit models\"; we follow the path-dependent nature of financial markets as defined by the industry's leading researchers.</li> </ul>"},{"location":"#references","title":"\ud83d\udcda References","text":"<ul> <li>L\u00f3pez de Prado, M. (2018). Advances in Financial Machine Learning. Wiley.</li> </ul> <p>     Developed with passion and mathematical rigor by   </p>       Francisco Puertos Rumayor"},{"location":"reference/config/providers/","title":"Data Providers Registry","text":""},{"location":"reference/config/providers/#finml_core.config.providers","title":"<code>finml_core.config.providers</code>","text":"<p>This module centralizes the configuration for all supported data sources. Its primary  goal is to enable total automation: if a provider is registered here, the  <code>MarketDataLoader</code> knows exactly how to interpret its columns without any user  intervention.</p>"},{"location":"reference/config/providers/#finml_core.config.providers--automated-workflow","title":"\ud83d\ude80 Automated Workflow","text":"<p>This registry acts as the bridge connecting the Loader with the  rest of the library. By selecting a valid <code>data_source</code>, the system automatically  configures column mappings and MultiIndex levels (Ticker and Date).</p>"},{"location":"reference/config/providers/#finml_core.config.providers--current-support","title":"\ud83d\udee0\ufe0f Current Support","text":"<p>Currently, we provide official support for a single provider, though the architecture  is designed to be easily scalable:</p> <ul> <li>yfinance: Configured by default to extract OHLCV data using the standard Yahoo Finance schema.</li> </ul> <pre><code>PROVIDERS = {\n    'yfinance': {\n        'col_map': {\n            'open': 'Open', 'high': 'High', 'low': 'Low',\n            'close': 'Close', 'volume': 'Volume'\n        },\n        'ticker_level': 'Ticker',\n        'date_level': 'Date'\n    }\n}\n</code></pre> <p>Which provider would you like to see next?</p> <p>We are actively working to expand this list to achieve \"plug-and-play\" integration with more sources. If you use a specific provider (such as Alpaca, Binance, or Bloomberg) and would like the workflow to be 100% automated for them, we would love to hear your suggestions to add them to the registry!</p> <p>You can reach out by:</p> <ul> <li>\ud83d\udee0\ufe0f Open GitHub Issue</li> <li>\u2709\ufe0f Email</li> <li>\ud83d\udcbc LinkedIn</li> </ul>"},{"location":"reference/data/loader/","title":"Loader","text":""},{"location":"reference/data/loader/#finml_core.data.loader","title":"<code>finml_core.data.loader</code>","text":""},{"location":"reference/data/loader/#finml_core.data.loader.MarketDataLoader","title":"<code>MarketDataLoader(source='yfinance')</code>","text":""},{"location":"reference/data/loader/#finml_core.data.loader.MarketDataLoader--automated-data-ingestor-and-standardizer","title":"Automated Data Ingestor and Standardizer.","text":"<p>This class acts as the primary gateway for raw market data. Its core mission  is to abstract the complexity of external APIs, transforming heterogeneous  data sources into the internal standardized Long-Format MultiIndex required by the entire library ecosystem.</p> <p>The engine ensures that regardless of the provider, the final output strictly  adheres to a <code>[Date, Ticker]</code> MultiIndex structure with standardized OCHLV columns.</p> <p>The constructor initializes the loader by selecting a specific data provider  registry. This setup determines the internal mapping logic that will be  applied during the standardization process.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Provider name from the  <code>PROVIDERS</code> registry.</p> <code>'yfinance'</code>"},{"location":"reference/data/loader/#finml_core.data.loader.MarketDataLoader.get_financial_data","title":"<code>get_financial_data(tickers, etf, start, end=None)</code>","text":"<p>Fetches and standardizes financial data from the configured source.</p> <p>This method acts as a high-level factory. It ensures that regardless of the  source's original API format, the output is consistently aligned and  ready for the <code>DatasetGenerator</code> or any other standalone class within the  library (e.g., <code>FeatureGenerator</code>, <code>TripleBarrierLabeling</code>).</p> <p>Parameters:</p> Name Type Description Default <code>tickers</code> <code>List[str]</code> <p>List of asset symbols to fetch.</p> required <code>etf</code> <code>str</code> <p>Reference ETF (e.g., '^GSPC') used to define the  market calendar and align trading days.</p> required <code>start</code> <code>str</code> <p>Start date/time. Supports various resolutions (e.g., <code>YYYY-MM-DD</code> or <code>YYYY-MM-DD HH:MM:SS</code>) depending on the providers capability.</p> required <code>end</code> <code>str</code> <p>End date/time. Supports the same resolutions  as <code>start</code>. Defaults to today.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A standardized MultiIndex DataFrame (Date, Ticker)  containing adjusted OHLCV data, ready for quantitative analysis.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the <code>source</code> provided during initialization is not  yet implemented in the data fetching logic.</p>"},{"location":"reference/metrics/indicators/","title":"Indicators","text":""},{"location":"reference/metrics/indicators/#finml_core.metrics.indicators","title":"<code>finml_core.metrics.indicators</code>","text":""},{"location":"reference/metrics/indicators/#finml_core.metrics.indicators.bollinger_bands","title":"<code>bollinger_bands(prices, window=20, num_std=2.0)</code>","text":"<p>Calculates Bollinger Bands and derived volatility metrics (%B and Bandwidth).</p> <p>Bollinger Bands consist of a middle band (SMA) and two outer bands calculated using the standard deviation of the price series.</p> Mathematical Formulas <ul> <li> \\[ \\text{MB}_t = \\mu_{P,n} \\] </li> <li> \\[ \\text{UB}_t = \\mu_{P,n} + (k \\cdot \\sigma_{P,n}) \\] </li> <li> \\[ \\text{LB}_t = \\mu_{P,n} - (k \\cdot \\sigma_{P,n}) \\] </li> </ul> Where <ul> <li>\\(\\mu_{P,n}\\): The rolling mean (SMA) of price \\(P\\) over window \\(n\\).</li> <li>\\(\\sigma_{P,n}\\): The rolling standard deviation of price \\(P\\) over                   window \\(n\\).</li> <li>\\(k\\): Standard deviation multiplier.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>Series</code> <p>Time series of asset prices.</p> required <code>window</code> <code>int</code> <p>Moving average window size. Defaults to 20.</p> <code>20</code> <code>num_std</code> <code>float</code> <p>Number of standard deviations (k).                        Defaults to 2.0.</p> <code>2.0</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A MultiIndex-compatible DataFrame containing:</p> <ul> <li><code>bb_middle</code>: The Simple Moving Average (SMA).</li> <li><code>bb_upper</code>: Upper volatility band.</li> <li><code>bb_lower</code>: Lower volatility band.</li> <li><code>bb_pct_b</code>: Price position relative to the bands               (1.0 = Upper, 0.0 = Lower).</li> <li><code>bb_width</code>: Normalized width of the bands, measuring               relative volatility.</li> </ul>"},{"location":"reference/metrics/indicators/#finml_core.metrics.indicators.macd","title":"<code>macd(prices, fast=12, slow=26, signal=9)</code>","text":"<p>Calculates the Moving Average Convergence Divergence (MACD).</p> <p>The MACD is a trend-following momentum indicator that shows the relationship between two exponential moving averages of an asset's price.</p> <p>Mathematical Formulas:</p> <ul> <li> \\[ \\text{MACD Line} =  \\text{EMA}_{fast}(P) - \\text{EMA}_{slow}(P) \\] </li> <li> \\[ \\text{Signal Line} = \\text{EMA}_{signal}(\\text{MACD Line}) \\] </li> <li> \\[ \\text{Histogram} = \\text{MACD Line} - \\text{Signal Line} \\] </li> <li> \\[ \\text{Relative Hist} = \\frac{\\text{Histogram}}{P} \\] </li> </ul> <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>Series</code> <p>Time series of asset prices.</p> required <code>fast</code> <code>int</code> <p>Fast EMA span. Defaults to 12.</p> <code>12</code> <code>slow</code> <code>int</code> <p>Slow EMA span. Defaults to 26.</p> <code>26</code> <code>signal</code> <code>int</code> <p>Signal EMA span. Defaults to 9.</p> <code>9</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing:</p> <ul> <li><code>macd_line</code>: The difference between fast and slow EMAs.</li> <li><code>macd_signal</code>: EMA of the MACD line (smoothing).</li> <li><code>macd_hist</code>: The distance between the MACD line and the                 signal line.</li> <li><code>macd_rel_hist</code>: Price-normalized histogram                     (stationary feature for ML).</li> </ul> Notes <ul> <li>EMA Calculation: Uses Standard EMA (\\(\\alpha = 2/(N+1)\\)).</li> <li>'macd_rel_hist' is a custom metric: Histogram / Price. This normalizes   the volatility relative to the asset price, useful for ML features.</li> <li>Why <code>adjust=False</code>? This mimics the recursive formula used in most   trading platforms: \\(y_t = (1-\\alpha)y_{t-1} + \\alpha x_t\\).   Using <code>adjust=True</code> (pandas default) would calculate weights based on   finite history, leading to values that diverge from standard market   indicators.</li> </ul>"},{"location":"reference/metrics/indicators/#finml_core.metrics.indicators.relative_volume","title":"<code>relative_volume(volume, window=20)</code>","text":"<p>Calculates Relative Volume (RVol).</p> <p>RVol measures the current trading activity relative to its historical average.  It is a key feature for identifying \"smart money\" institutional activity  and confirming price breakouts.</p> Mathematical Formula \\[ \\text{RVol}_t = \\frac{V_t}{\\frac{1}{n} \\sum_{i=0}^{n-1} V_{t-i}} \\] Where <ul> <li>\\(V_t\\): Trading volume at time \\(t\\).</li> <li>\\(n\\): Lookback window (moving average period).</li> </ul> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>Series</code> <p>Time series of trading volume.</p> required <code>window</code> <code>int</code> <p>Lookback window. Defaults to 20                     (approx. 1 trading month).</p> <code>20</code> <p>Returns:</p> Type Description <code>Series</code> <p>A ratio indicating relative volume.</p> <ul> <li>Values &gt; 1.0: High abnormal activity (Surge in interest).</li> <li>Values &lt; 1.0: Low activity (Typical of consolidations).</li> </ul> Notes <ul> <li>Why 20 days? Represents approximately one trading month.</li> <li>Stationarity: RVol is a stationary feature, making it highly    suitable for Machine Learning models without further differencing.</li> <li>Numerical Stability: Uses <code>EPSILON</code> (1e-6) replacement for zero    moving averages to prevent <code>inf</code> values in low-liquidity assets.</li> </ul>"},{"location":"reference/metrics/indicators/#finml_core.metrics.indicators.rsi","title":"<code>rsi(prices, period=14)</code>","text":"<p>Calculates the Relative Strength Index (RSI) using Wilder's Smoothing.</p> <p>The RSI calculates a ratio of the recent upward price movements to the absolute price movements.</p> \\[ RSI = 100 - \\frac{100}{1 + RS} \\] <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>Series</code> <p>Time series of asset prices.</p> required <code>period</code> <code>int</code> <p>The lookback period.  Defaults to 14 (Standard industry value proposed by Wilder).</p> <code>14</code> <p>Returns:</p> Type Description <code>Series</code> <p>The RSI values (0-100).</p> Notes <p>This implementation uses Wilder's Smoothing (\\(\\alpha = 1/N\\)), which is  standard in technical analysis. This creates a recursive dependency, so early values may vary slightly depending on the data start point.</p> <p>Why <code>adjust=False</code>? This mimics the recursive formula used in most trading platforms: \\(y_t = (1-\\alpha)y_{t-1} + \\alpha x_t\\). Using <code>adjust=True</code> (pandas default) would calculate weights based on finite history, leading to values that diverge from standard market indicators.</p>"},{"location":"reference/metrics/performance/","title":"Performance","text":""},{"location":"reference/metrics/performance/#finml_core.metrics.performance","title":"<code>finml_core.metrics.performance</code>","text":""},{"location":"reference/metrics/performance/#finml_core.metrics.performance.sharpe_ratio","title":"<code>sharpe_ratio(returns, risk_free_rate=0.0, periods=252)</code>","text":"<p>Calculates the annualized Sharpe Ratio (Ex-post).</p> <p>The Sharpe Ratio evaluates the risk-adjusted performance of an investment  by subtracting the risk-free rate from the investment's return and  dividing the result by the investment's standard deviation (volatility).</p> Mathematical Formula \\[ S = \\frac{R_p - R_f}{\\sigma_p} \\cdot \\sqrt{T} \\] Where <ul> <li>\\(R_p\\): Average period return.</li> <li>\\(R_f\\): Risk-free rate per period.</li> <li>\\(\\sigma_p\\): Standard deviation of period returns.</li> <li>\\(T\\): Annualization factor (e.g., 252 for daily data).</li> </ul> <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>Series</code> <p>Time series of asset returns                   (simple returns recommended).</p> required <code>risk_free_rate</code> <code>float</code> <p>Annualized risk-free rate                               (e.g., 0.04 for 4%). Defaults to 0.0.</p> <code>0.0</code> <code>periods</code> <code>int</code> <p>Annualization factor. (252 for daily, 12 for                      monthly). Defaults to 252.</p> <code>252</code> <p>Returns:</p> Type Description <code>float</code> <p>The annualized Sharpe Ratio.</p> Interpretability <ul> <li>&lt; 1.0: Suboptimal risk-adjusted return.</li> <li>1.0 - 1.9: Acceptable / Good.</li> <li>2.0 - 2.9: Superior / Very Good.</li> <li>&gt; 3.0: Exceptional (often seen in High-Frequency Trading).</li> </ul>"},{"location":"reference/metrics/statistics/","title":"Statistics","text":""},{"location":"reference/metrics/statistics/#finml_core.metrics.statistics","title":"<code>finml_core.metrics.statistics</code>","text":""},{"location":"reference/metrics/statistics/#finml_core.metrics.statistics.log_returns","title":"<code>log_returns(prices, period=1)</code>","text":"<p>Calculates the logarithmic (continuously compounded) returns.</p> <p>Computes the log return as the difference between the natural logarithm of the price at time t and the natural logarithm of the price at time t-period.</p> \\[r_t = \\ln(P_t) - \\ln(P_{t-n})\\] <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>Series</code> <p>Time series of asset prices. Must be strictly                 positive.</p> required <code>period</code> <code>int</code> <p>The shift period to calculate returns.  Defaults to 1 (daily returns if data is daily).</p> <code>1</code> <p>Returns:</p> Type Description <code>Series</code> <p>Series of log returns. The first 'period' values will be NaN.</p> Notes <p>Log returns are preferred in quantitative finance because:</p> <ol> <li>Time Additivity: Sum of log returns equals the total period return.</li> <li>Statistical Properties: They are often assumed to be normally                            distributed.</li> </ol>"},{"location":"reference/metrics/statistics/#finml_core.metrics.statistics.rolling_mean","title":"<code>rolling_mean(prices, window)</code>","text":"<p>Calculates the Simple Moving Average (SMA).</p> <p>Computes the unweighted mean of the previous 'window' data points.</p> \\[ \\mu_t = \\frac{1}{n} \\sum_{i=0}^{n-1} P_{t-i} \\] <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>Series</code> <p>Time series data.</p> required <code>window</code> <code>int</code> <p>The size of the moving window.</p> required <p>Returns:</p> Type Description <code>Series</code> <p>The rolling mean. The first 'window-1' values will be NaN.</p>"},{"location":"reference/metrics/statistics/#finml_core.metrics.statistics.rolling_std","title":"<code>rolling_std(prices, window)</code>","text":"<p>Calculates the Moving Standard Deviation.</p> <p>Computes the standard deviation of the previous 'window' data points. Often used as a measure of dynamic volatility (e.g., Bollinger Bands width).</p> \\[\\sigma_t = \\sqrt{\\frac{1}{n-1} \\sum_{i=0}^{n-1} (P_{t-i} - \\bar{x}_t)^2}\\] <p>Where:</p> <ul> <li>\\(\\sigma_t\\): Rolling standard deviation at time \\(t\\).</li> <li>\\(n\\): Lookback period (window size).</li> <li>\\(P_{t-i}\\): Observation at time \\(t-i\\).</li> <li>\\(\\bar{x}_t\\): Moving average (mean) of the window at time \\(t\\).</li> </ul> <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>Series</code> <p>Time series data.</p> required <code>window</code> <code>int</code> <p>The size of the moving window.</p> required <p>Returns:</p> Type Description <code>Series</code> <p>The rolling standard deviation.</p>"},{"location":"reference/metrics/statistics/#finml_core.metrics.statistics.simple_returns","title":"<code>simple_returns(prices, period=1)</code>","text":"<p>Calculates the arithmetic (simple) returns.</p> \\[R_t = \\frac{P_t}{P_{t-n}} - 1\\] <p>Parameters:</p> Name Type Description Default <code>prices</code> <code>Series</code> <p>Time series of asset prices.</p> required <code>period</code> <code>int</code> <p>The shift period. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>Series</code> <p>Series of simple returns.</p>"},{"location":"reference/metrics/statistics/#finml_core.metrics.statistics.volatility","title":"<code>volatility(returns, annualize=True, scale=252)</code>","text":"<p>Calculates the volatility (sample standard deviation) of a return series.</p> <p>Optionally applies an annualization factor.</p> \\[ \\sigma_{annual} = \\sigma_{period} \\times \\sqrt{T} \\] <p>Parameters:</p> Name Type Description Default <code>returns</code> <code>Series</code> <p>Time series of asset returns (log or simple).</p> required <code>annualize</code> <code>bool</code> <p>If True, scales the volatility to an  annual figure. Defaults to True.</p> <code>True</code> <code>scale</code> <code>int</code> <p>The annualization factor.  Use 252 for daily data, 12 for monthly data. Defaults to 252.</p> <code>252</code> <p>Returns:</p> Type Description <code>float</code> <p>The standard deviation of the series.</p> Notes <p>This function uses N-1 degrees of freedom (sample standard deviation), which is the default behavior in pandas.std().</p>"},{"location":"reference/model_selection/split/","title":"Split","text":""},{"location":"reference/model_selection/split/#finml_core.model_selection.split","title":"<code>finml_core.model_selection.split</code>","text":""},{"location":"reference/model_selection/split/#finml_core.model_selection.split.PurgedKFold","title":"<code>PurgedKFold(n_splits, t1, date_level, pct_embargo=0.01)</code>","text":"<p>Cross-Validation with Purging and Embargo for Financial Time Series.</p> <p>Implements the methodology proposed by Marcos L\u00f3pez de Prado in  \"Advances in Financial Machine Learning\" (Chapter 7). Standard K-Fold  CV assumes IID data, which is false in finance due to overlapping labels  and serial correlation.</p> This class prevents data leakage through two mechanisms <ol> <li>Purging: Removes training observations whose labels overlap in time  with the test set.</li> <li>Embargo: Eliminates a period immediately following the test set  to handle auto-correlated residuals.</li> </ol> Mathematical Overlap Condition <p>A training observation is purged if its interval \\([t_{i,0}, t_{i,1}]\\)  overlaps with the test interval \\([T_{j,0}, T_{j,1}]\\): $$ (t_{i,0} \\le T_{j,1}) \\land (t_{i,1} \\ge T_{j,0}) $$</p> <p>Attributes:</p> Name Type Description <code>n_splits</code> <code>int</code> <p>Number of folds.</p> <code>t1</code> <code>Series</code> <p>End timestamps of labels (Vertical Barriers).</p> <code>date_level</code> <code>str</code> <p>MultiIndex level name for timestamps.</p> <code>pct_embargo</code> <code>float</code> <p>Percentage of total timeframe for the embargo.</p> Note <p>Sklearn Compatibility: Works as a drop-in replacement for KFold in  GridSearchCV and cross_val_score.</p>"},{"location":"reference/model_selection/split/#finml_core.model_selection.split.PurgedKFold.split","title":"<code>split(X, y, groups=None)</code>","text":"<p>Generates indices to split data into training and test sets.</p> Process <ol> <li>Temporal Grouping: Groups data by unique dates to maintain  chronological integrity.</li> <li>Interval Analysis: Evaluates the <code>t1</code> (label span) of each  observation.</li> <li>Purge &amp; Embargo: Drops training indices that fail the  non-overlap condition against the current test fold.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>DataFrame</code> <p>Features dataset with MultiIndex.</p> required <code>y</code> <code>Series</code> <p>Target variable. Defaults to None.</p> required <code>groups</code> <p>Compatibility placeholder.</p> <code>None</code> <p>Yields:</p> Type Description <code>ndarray</code> <p>Integer indices for the training set.</p> <code>ndarray</code> <p>Integer indices for the test set.</p>"},{"location":"reference/model_selection/split/#finml_core.model_selection.split.purged_train_test_split","title":"<code>purged_train_test_split(X, y, t1, date_level, test_size=0.2, pct_embargo=0.01)</code>","text":"<p>Chronological split with financial purging and embargo.</p> <p>Performs a non-shuffled temporal split (Past -&gt; Train, Future -&gt; Test)  and applies a quarantine period to ensure the test set is strictly  independent of the training data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>DataFrame</code> <p>Features dataset.</p> required <code>y</code> <code>Series</code> <p>Target labels.</p> required <code>t1</code> <code>Series</code> <p>Timestamps of label ends (Vertical Barriers).</p> required <code>date_level</code> <code>str</code> <p>MultiIndex level name for timestamps.</p> required <code>test_size</code> <code>float</code> <p>Proportion of data for testing. Defaults to 0.2.</p> <code>0.2</code> <code>pct_embargo</code> <code>float</code> <p>Total timeline percentage for embargo.                   Defaults to 0.01 (1%).</p> <code>0.01</code> <p>Returns:</p> Type Description <code>Tuple</code> <ul> <li>X_train (pd.DataFrame): Purged features.</li> <li>y_train (pd.Series): Purged labels.</li> <li>X_test (pd.DataFrame): Test features.</li> <li>y_test (pd.Series): Test labels.</li> </ul>"},{"location":"reference/pipelines/data_factory/","title":"Data Factory","text":""},{"location":"reference/pipelines/data_factory/#finml_core.pipelines.data_factory","title":"<code>finml_core.pipelines.data_factory</code>","text":""},{"location":"reference/pipelines/data_factory/#finml_core.pipelines.data_factory.DatasetGenerator","title":"<code>DatasetGenerator(data_source=None, custom_provider=None, feature_config=None, feature_selection=None, label_config=None)</code>","text":"<p>Master Orchestrator for Financial Machine Learning Pipelines.</p> This class centralizes the end-to-end workflow of a quantitative trading strategy <ol> <li>Data Acquisition: Either via automated download or manual injection.</li> <li>Cleaning: Handles MultiIndex alignment, NaNs, and infinite values.</li> <li>Feature Engineering: Generates technical indicators and temporal lags.</li> <li>Labeling: Executes the Triple Barrier Method for target definition.</li> <li>Consolidation: Aligns \\(X\\) and \\(y\\) by removing inconsistent 'warm-up' periods.</li> </ol>"},{"location":"reference/pipelines/data_factory/#finml_core.pipelines.data_factory.DatasetGenerator--operation-modes","title":"Operation Modes","text":"<p>The generator adapts to two primary user workflows:</p> <ul> <li>Automated Mode (Beginner-Friendly): Uses pre-configured mappings from the      internal registry. You only need to provide a <code>data_source</code> (e.g., 'yfinance')      and the list of tickers in the <code>run</code> method.</li> <li>Custom Mode (Pro/Injected): Designed for users with proprietary datasets      or unsupported APIs. By providing a <code>custom_provider</code> dictionary, the      orchestrator switches to an injection-only logic, requiring a pre-loaded      DataFrame in the <code>run</code> method.</li> </ul> <p>Attributes:</p> Name Type Description <code>analysis_data</code> <code>DataFrame</code> <p>Full dataset available after <code>run()</code>,  containing original OHLCV, all indicators, and labeling details.</p>"},{"location":"reference/pipelines/data_factory/#finml_core.pipelines.data_factory.DatasetGenerator--pipeline-configuration-engine-setup","title":"Pipeline Configuration &amp; Engine Setup","text":"<p>Instantiating this class initializes the core modular engines required for  the full data lifecycle. This constructor acts as a factory, setting up  the internal instances of <code>MarketDataLoader</code>, <code>FeatureGenerator</code>,  <code>TripleBarrierLabeling</code>, and <code>DataCleaner</code> based on the selected mode.</p> <p>It determines whether the pipeline will operate in 'Automated' mode  (leveraging predefined provider registries) or 'Custom' mode  (handling user-injected datasets and coordinate maps).</p> <p>Parameters:</p> Name Type Description Default <code>data_source</code> <code>str</code> <p>Name of the provider in  <code>PROVIDERS</code>     registry. Defaults to 'yfinance'.</p> <code>None</code> <code>custom_provider</code> <code>Dict[str, Any]</code> <p>Custom coordinate map. If provided, ignores <code>data_source</code>.  Must contain <code>col_map</code>, <code>ticker_level</code>, and <code>date_level</code>.</p> <p>Example:</p> <p><pre><code>{\n    'col_map': {\n        'open': 'Open', 'high': 'High', 'low': 'Low',\n        'close': 'Close', 'volume': 'Volume'\n    },\n    'ticker_level': 'Ticker',\n    'date_level': 'Date'\n}\n</code></pre> which is 'yfinance' mapping.</p> <code>None</code> <code>feature_config</code> <code>Dict[str, Dict[str, Any]]</code> <p>Technical indicator parameters (e.g., <code>rsi</code>, <code>bollinger</code>).  If None, uses   <code>compute_indicators</code>  defaults from <code>FeatureGenerator</code> class.</p> <code>None</code> <code>feature_selection</code> <code>Dict[str, List[int]]</code> <p>The final 'filter' for the matrix. Defines which metrics and  how many lags to include in \\(X\\). If None, uses   <code>construct_feature_matrix</code>  defaults from <code>FeatureGenerator</code> class.</p> <code>None</code> <code>label_config</code> <code>Dict[str, Any]</code> <p>Hyperparameters for the Triple Barrier Method. If None, uses  <code>compute_outcomes</code>  defaults from <code>TripleBarrierLabeling</code> class.</p> <code>None</code>"},{"location":"reference/pipelines/data_factory/#finml_core.pipelines.data_factory.DatasetGenerator.run","title":"<code>run(tickers=None, etf_reference=None, start_date=None, end_date=None, df_input=None)</code>","text":"<p>Executes the modeling pipeline to produce model-ready matrices.</p> <p>This method orchestrates the full data lifecycle. It follows a strict  Priority Logic:</p> <ol> <li>If <code>custom_provider</code> was used at <code>__init__</code>, it requires <code>df_input</code>.</li> <li>If <code>data_source</code> was used, it attempts to download data using      <code>tickers</code>, <code>etf_reference</code>, and <code>start_date</code>.</li> </ol> <p>Data Structure Requirement (MultiIndex)</p> <p>Whether injected via <code>df_input</code> or downloaded, the internal engine  requires a MultiIndex DataFrame with levels corresponding to  <code>ticker_level</code> and <code>date_level</code>. </p> <p>Standard format: <code>[Date (DatetimeIndex), Ticker (str)]</code>.</p> <p>Parameters:</p> Name Type Description Default <code>tickers</code> <code>List[str]</code> <p>Asset symbols to fetch. Required if <code>df_input</code> is None and <code>custom_provider</code> was specified.</p> <code>None</code> <code>etf_reference</code> <code>str</code> <p>Reference symbol (e.g., '^GSPC') to align market holidays.</p> <code>None</code> <code>start_date</code> <code>str</code> <p>Start of the historical period (YYYY-MM-DD hhss).</p> <code>None</code> <code>end_date</code> <code>str</code> <p>End of the period. Defaults to current date.</p> <code>None</code> <code>df_input</code> <code>DataFrame</code> <p>Pre-loaded MultiIndex DataFrame.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple</code> <ul> <li>X (pd.DataFrame): Final Feature Matrix with selected      metrics and lags.</li> <li>y (pd.DataFrame): Target labels (target_side) aligned      with \\(X\\).</li> </ul> <p>Index Alignment &amp; Trimming:</p> <p>The pipeline performs a bidirectional trim      to ensure a clean, MultiIndex-aligned dataset. It removes the      Warm-up Period at the beginning (caused by rolling metrics like      volatility and indicators) and the Horizon Gap at the end (due to      the forward-looking nature of triple-barrier labels). This ensures      that \\(X\\) and \\(y\\) contain only fully realized, non-null observations      ready for machine learning.</p>"},{"location":"reference/processing/cleaning/","title":"Cleaning","text":""},{"location":"reference/processing/cleaning/#finml_core.processing.cleaning","title":"<code>finml_core.processing.cleaning</code>","text":""},{"location":"reference/processing/cleaning/#finml_core.processing.cleaning.DataCleaner","title":"<code>DataCleaner(ticker_level, date_level, method='ffill')</code>","text":"<p>Module responsible for data sanitization and stability.</p> <p>Standardizes the handling of infinities (infs) and null values (NaNs)  to ensure the numerical stability of the pipeline before ML ingestion.</p> Key Features <ol> <li>Multi-Asset Safety: Applies operations per-ticker to prevent data                        leakage.</li> <li>Look-ahead Bias Prevention: Uses conservative filling methods                                (ffill limit=1).</li> <li>Strict Validation: Raises errors if data quality standards                       are not met.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>ticker_level</code> <code>str</code> <p>Name of the MultiIndex level containing the asset identifiers (e.g., 'Ticker').</p> required <code>date_level</code> <code>str</code> <p>Name of the MultiIndex level containing the timestamps (e.g., 'Date'). Required for re-indexing  during edge trimming.</p> required <code>method</code> <code>str</code> <p>Strategy for handling NaNs. for now only 'ffill'           (Forward Fill) is supported as it is standard in           in financial time series to handle minor gaps           (e.g., holidays) without look-ahead bias.</p> <code>'ffill'</code>"},{"location":"reference/processing/cleaning/#finml_core.processing.cleaning.DataCleaner.validate_and_clean","title":"<code>validate_and_clean(df)</code>","text":"<p>Execution Protocol: Strict Sanitization.</p> <p>Runs the data through a 4-stage quality gate to ensure numerical integrity.</p> Protocol Steps <ol> <li>Trim Edges: Removes leading/trailing NaNs (warm-up periods).</li> <li>Fill Gaps: Applies limited forward fill for internal gaps.</li> <li>NaN Validation: checks for remaining Nulls;                    raises Error if found.</li> <li>Inf Validation: checks for Infinite values;                    raises Error if found.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame (Raw or Feature Matrix).                Must have a MultiIndex (Date, Ticker).</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A clean, numerically stable DataFrame ready for            modeling.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If NaNs persist after cleaning or if Infs are detected.</p>"},{"location":"reference/processing/features/","title":"Features","text":""},{"location":"reference/processing/features/#finml_core.processing.features","title":"<code>finml_core.processing.features</code>","text":""},{"location":"reference/processing/features/#finml_core.processing.features.FeatureGenerator","title":"<code>FeatureGenerator(col_map, ticker_level, config=None)</code>","text":"<p>Orchestrates feature engineering pipeline from raw data.</p> This class handles <ol> <li>Column Mapping (Standardizing input names).</li> <li>Feature Calculation (Calling metrics module).</li> <li>Lag Generation (Per-feature customization).</li> <li>Multi-asset grouping (Stacking support).</li> </ol> <p>Supported Metrics &amp; Configuration Keys:</p> <ul> <li><code>log_ret</code>:<ul> <li>period (int): Return period (default: 1).</li> </ul> </li> <li><code>rsi</code>:<ul> <li>period (int): Lookback period. (Default: 14).</li> </ul> </li> <li><code>bollinger</code>:<ul> <li>window (int): Moving average window (default: 20).</li> <li>std (float): Standard deviations (default: 2.0).</li> </ul> </li> <li><code>macd</code>:<ul> <li>fast (int): Fast EMA (default: 12).</li> <li>slow (int): Slow EMA (default: 26).</li> <li>signal (int): Signal EMA (default: 9).</li> </ul> </li> <li><code>rvol</code>:<ul> <li>window (int): SMA window (default: 20).</li> </ul> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>col_map</code> <code>Dict</code> <p>Maps standard names to dataframe columns.</p> <p>Example: <pre><code>    {\n        'open': 'Open',\n        'high': 'High',\n        'low': 'Low',\n        'close': 'Close',\n        'volume': 'Volume'\n    }\n</code></pre> which is yfinance standard.</p> required <code>ticker_level</code> <code>str</code> <p>Name of the MultiIndex level containing the asset identifiers (e.g., 'Ticker').</p> required <code>config</code> <code>Dict</code> <p>Configuration dictionary.</p> <p>Defaults to: <pre><code>    {\n        'log_ret': {'period': 1},\n        'rsi': {'period': 14},\n        'bollinger': {'window': 20, 'std': 2.0},\n        'macd': {'fast': 12, 'slow': 26, 'signal': 9},\n        'rvol': {'window': 20}\n    }\n</code></pre> which is the market standard configuration.</p> <code>None</code> Note <p>Your DataFrame must include 'Close' and 'Volume' columns to compute all supported metrics.</p>"},{"location":"reference/processing/features/#finml_core.processing.features.FeatureGenerator.compute_indicators","title":"<code>compute_indicators(df)</code>","text":"<p>Phase 1: Feature Calculation Engine</p> <p>This method orchestrates the vectorization of technical indicators across  a MultiIndex DataFrame. It ensures that calculations are performed  independently for each ticker to prevent look-ahead bias and cross-sectional  data leakage.</p> The process follows a strict 3-step pipeline <ol> <li>Validation: Verifies that the MultiIndex structure and required  columns (mapped via <code>col_map</code>) exist before computation.</li> <li>Grouped Transformation: Uses <code>groupby().transform()</code> or <code>apply()</code>  to isolate time-series calculations by asset.</li> <li>Feature Expansion: Dynamically appends new analytical columns  to the dataset while preserving the original index.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame with a MultiIndex (Date, Ticker)                 and raw OHLCV columns.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A copy of the input DataFrame enriched with:</p> <ul> <li>Momentum: Log Returns, RSI, RSI Change.</li> <li>Volatility: Bollinger Bands (Middle, Upper, Lower, %B, Bandwidth).</li> <li>Trend: MACD (Line, Signal, Histogram, Relative Histogram).</li> <li>Volume: Relative Volume (RVol).</li> </ul> <p>Raises:</p> Type Description <code>KeyError</code> <p>If a configured indicator lacks its required raw column        mapping (e.g., trying to calculate RSI without a 'close' column).</p> <code>ValueError</code> <p>If the <code>ticker_level</code> is not correctly identified in the Index.</p> Note <p>This method is \"non-destructive\" regarding rows; it calculates metrics  for all available data. Handling of <code>NaN</code> values generated by rolling  windows is deferred to Phase 2 (Filtering).</p>"},{"location":"reference/processing/features/#finml_core.processing.features.FeatureGenerator.construct_feature_matrix","title":"<code>construct_feature_matrix(df_metrics, selection=None)</code>","text":"<p>Phase 2: Selection &amp; Lagging</p> <p>Refines the calculated metrics into a finalized feature matrix. This phase handles the dimensionality of the input space by selecting specific columns and generating lagged observations to capture autocorrelation and temporal dependencies.</p> Process <ol> <li>Feature Pruning: Filters the dataset to keep only the metrics  specified in the <code>selection</code> dictionary.</li> <li>MultiIndex Lagging: Generates \\(t-n\\) observations using  <code>groupby().shift()</code>. This ensures that lags are calculated per asset, preventing cross-contamination between different tickers.</li> <li>Feature Expansion: Creates new columns with the suffix <code>_lag_n</code>.</li> </ol> <p>Machine Learning Recommendations</p> <p>For most ML models (Random Forest, XGBoost, etc.), it is highly recommended to  use Stationary Features. Using raw prices or moving averages (like <code>bb_middle</code>)  can lead to poor generalization due to unit roots. </p> <p>Recommended Stationary Set (Default):</p> <ul> <li>Returns: <code>log_ret</code> (captures percentage change).</li> <li>Momentum: <code>rsi</code>, <code>rsi_diff</code> (bounded between 0-100).</li> <li>Volatility: <code>bb_pct_b</code>, <code>bb_width</code> (normalized volatility).</li> <li>Trend: <code>macd_rel_hist</code> (price-normalized momentum).</li> <li>Volume: <code>rvol</code> (normalized activity).</li> </ul> <p>Parameters:</p> Name Type Description Default <code>df_metrics</code> <code>DataFrame</code> <p>Enriched MultiIndex DataFrame from Phase 1 (<code>generate()</code> function).</p> required <code>selection</code> <code>Dict[str, List[int]]</code> <p>Dictionary mapping feature names to a list of desired lags.</p> <ul> <li>Use <code>[]</code> for the current value (\\(t\\)) only.</li> <li>Use <code>[1, 2]</code> for current value plus two previous steps.</li> </ul> <p>Defaults to:</p> <pre><code>{\n    'log_ret': [],\n    'rsi': [],\n    'rsi_diff': [],\n    'bb_pct_b': [],\n    'bb_width': [],\n    'macd_rel_hist': [],\n    'rvol': []\n}\n</code></pre> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The finalized Feature Matrix (X). Columns are ordered by feature  then by lag (e.g., <code>rsi</code>, <code>rsi_lag_1</code>, <code>rsi_lag_2</code>).</p> Notes <ul> <li>Temporal Dynamics: Adding lags is essential for non-sequential  models (like Random Forest or XGBoost) to \"see\" the trend.</li> <li>Data Leakage: This method preserves the MultiIndex to ensure  that <code>shift</code> operations never mix data from different tickers at  the boundaries.</li> </ul>"},{"location":"reference/processing/labeling/","title":"Labeling","text":""},{"location":"reference/processing/labeling/#finml_core.processing.labeling","title":"<code>finml_core.processing.labeling</code>","text":""},{"location":"reference/processing/labeling/#finml_core.processing.labeling.TripleBarrierLabeling","title":"<code>TripleBarrierLabeling(col_map, ticker_level, date_level, config=None)</code>","text":"<p>Labels financial time-series using the Triple Barrier Method (TBM).</p> <p>Unlike standard fixed-horizon labeling, TBM creates dynamic labels based on  volatility-adjusted price targets. It effectively captures the path-dependent  nature of financial assets by monitoring three concurrent barriers:</p> <ol> <li>Upper Barrier (Take Profit): Hit when price appreciation reaches     \\(P_t \\cdot (1 + \\text{tp}_{\\text{mult}} \\cdot \\sigma_t)\\).</li> <li>Lower Barrier (Stop Loss): Hit when price depreciation reaches     \\(P_t \\cdot (1 - \\text{sl}_{\\text{mult}} \\cdot \\sigma_t)\\).</li> <li>Vertical Barrier (Time Limit): Hit when neither price barrier is     touched within a fixed window \\(T\\).</li> </ol> Mathematical Outcomes <ul> <li>1 (Long): Upper barrier hit first.</li> <li>-1 (Short): Lower barrier hit first.</li> <li>0 (Hold): Vertical barrier (Time Limit) reached.</li> </ul> Note <p>This implementation is optimized for MultiIndex DataFrames (Ticker, Date)  and uses vectorized NumPy operations for the internal path-scanning loop.</p> <p>Parameters:</p> Name Type Description Default <code>col_map</code> <code>Dict</code> <p>Mapping for OHLCV columns.</p> <p>Required to compute the labeling:     <code>{'close': ..., 'high': ..., 'low': ...}</code></p> <p>Example:     <pre><code>{\n    'close': 'Close',\n    'high': 'High',\n    'low': 'Low',\n}\n</code></pre> which is yfinance standard.</p> required <code>ticker_level</code> <code>str</code> <p>MultiIndex level name for asset identifiers (e.g., 'Ticker').</p> required <code>date_level</code> <code>str</code> <p>MultiIndex level name for timestamps (e.g., 'Date').</p> required <code>config</code> <code>Dict[str, Any]</code> <p>Hyperparameters for the barriers.</p> Key Type Default Description <code>stop_loss_multiplier</code> float 2.0 Volatility multiplier for SL. <code>take_profit_multiplier</code> float 2.0 Volatility multiplier for TP. <code>time_limit</code> int 10 Max periods to hold (Vertical Barrier). <code>vol_span</code> int 100 Span for EWM Volatility calculation. <code>None</code>"},{"location":"reference/processing/labeling/#finml_core.processing.labeling.TripleBarrierLabeling.compute_outcomes","title":"<code>compute_outcomes(df)</code>","text":"<p>Executes the Triple Barrier labeling process across all assets.</p> This method orchestrates the full pipeline <ol> <li>Volatility Normalization: Computes dynamic \\(\\sigma_t\\) per ticker.</li> <li>MultiIndex Grouping: Isolates price paths by asset to prevent  cross-ticker data leakage during barrier scanning.</li> <li>Numpy-Vectorized Search: Triggers the internal search engine for  first-touch events on future price paths.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>MultiIndex DataFrame containing price series.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame indexed like <code>df</code> with labeling results:</p> <ul> <li><code>target_side</code>: The final label {1, 0, -1}.</li> <li><code>transaction_return</code>: Unrealized return at the touch moment.</li> <li><code>t1</code>: Timestamp when the first barrier was hit.</li> <li><code>upper_barrier</code> &amp; <code>lower_barrier</code>: The volatility-adjusted price levels.</li> <li><code>time_to_barrier</code>: Integer steps taken to reach the outcome.</li> <li><code>both_barriers_hit</code>: Boolean flag for high-volatility gap cases.</li> </ul> <p>Raises:</p> Type Description <code>KeyError</code> <p>If required columns or MultiIndex levels are missing.</p>"}]}