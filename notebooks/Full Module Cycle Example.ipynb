{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e360abd",
   "metadata": {},
   "source": [
    "# Pending\n",
    "\n",
    "- Labeling revisar pagina\n",
    "- hacer pagina pricipal (index.md) para processing, indicando como se pueden usar en conjunto\n",
    "\n",
    "- tal vez despues hacer una pagina principal de entre todas, o en la misma pagina principal, indicar cual seria el uso ideal (el proceso a seguir), en caso de que no utilizaran a los\n",
    "proveedores disponibles como data source y tuvieran sus propios datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec6e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our First Pipeline\n",
    "from finml_core.pipelines.data_factory import DatasetGenerator\n",
    "# Importing Financial Splitting Methods\n",
    "from finml_core.model_selection.split import PurgedKFold, purged_train_test_split\n",
    "\n",
    "# External Libraries\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning external modules\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee8745e",
   "metadata": {},
   "source": [
    "## Config for the Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3a53c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-08"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "max(0, 0.00000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167ab161",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241;43m100\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "100/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b923ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "# Choosing financial and market theoretical metrics that we want as our features.\n",
    "features_config = {\n",
    "    \"log_ret\": dict(period=1),\n",
    "    \"rsi\": dict(period=14),\n",
    "    \"bollinger\": dict(window=20, std=2.0),\n",
    "    \"macd\": dict(fast=12, slow=26, signal=9),\n",
    "    \"rvol\": dict(window=20)\n",
    "}\n",
    "\n",
    "# Choosing metrics an calculations that we're going to choose as our features,\n",
    "# and including lag 5 for al our features\n",
    "# The following are the most recomended metrics to use as featues.\n",
    "feature_selection = {\n",
    "    'log_ret': [],\n",
    "    'rsi': [],\n",
    "    'rsi_diff': [],\n",
    "    'bb_pct_b': [],\n",
    "    'bb_width': [],\n",
    "    'macd_rel_hist': [],\n",
    "    'rvol': []\n",
    "}\n",
    "\n",
    "# 5 lags of information per feature\n",
    "for sel in feature_selection:\n",
    "    feature_selection[sel] = [i for i in range(1, 4)]\n",
    "\n",
    "# Setting parameters to compute the triple barrier method labeling\n",
    "label_config = dict(\n",
    "    stop_loss_multiplier = 1,\n",
    "    take_profit_multiplier = 1,\n",
    "    time_limit = 10,\n",
    "    vol_span = 50\n",
    ")\n",
    "\n",
    "# Setting the desired stocks to download and the start date, as well as the\n",
    "# etf reference date\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'AVGO']\n",
    "start = '2015-01-01'\n",
    "etf_reference = '^GSPC'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f5a92c",
   "metadata": {},
   "source": [
    "## Generating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a6883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Starting Ingestion (1 tickers) ---\n",
      "Downloading 1 tickers + ^GSPC reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. Generating Features (X) ---\n",
      "--- 3. Generating Labels (y) ---\n",
      "--- 4. Consolidating & Cleaning ---\n",
      "--- Pipeline Finished. Final Dataset: 2708 rows ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset generator instance\n",
    "dataset_generator = DatasetGenerator(\n",
    "    data_source='yfinance',\n",
    "    feature_config=features_config,\n",
    "    feature_selection=feature_selection,\n",
    "    label_config=label_config\n",
    ")\n",
    "\n",
    "# Getting X and Y\n",
    "X, y = dataset_generator.run(\n",
    "    tickers=tickers,\n",
    "    etf_reference=etf_reference,\n",
    "    start_date=start\n",
    ")\n",
    "\n",
    "# This contains all the different calculations made by the feature and the\n",
    "# labeling modules, excluding the lags\n",
    "analysis_data = dataset_generator.analysis_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be361171",
   "metadata": {},
   "source": [
    "## Split Data into Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40041260",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = purged_train_test_split(\n",
    "    X, y,\n",
    "    t1=analysis_data['t1'],\n",
    "    date_level='Date',\n",
    "    test_size=0.2,\n",
    "    pct_embargo=0.01\n",
    ")\n",
    "\n",
    "# Obtain training \"end date\" for each label, for PurgedKFold\n",
    "training_mask = analysis_data.index.isin(X_train.index)\n",
    "t1 = analysis_data.loc[training_mask, 't1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de19df7",
   "metadata": {},
   "source": [
    "## Purged K-Fold CV Example with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c427927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados de PurgedKFold ---\n",
      "Scores por Fold: [0.47689464 0.43738447 0.48544362 0.41226852 0.45601852]\n",
      "Accuracy Promedio: 45.36%\n",
      "Desviación Estándar: 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    5.4s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Creating purged k-fold cross validation instance\n",
    "purged_cv = PurgedKFold(\n",
    "    n_splits=5,             # Number of folds\n",
    "    t1=analysis_data['t1'], # labels exit dates\n",
    "    date_level='Date',      # Date level index reference\n",
    "    pct_embargo=0.01        # Pct. Embargo\n",
    ")\n",
    "\n",
    "# Crearting random forest instance\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Computing Purged K-Fold Cross Validation and Calculating Scores\n",
    "scores = cross_val_score(\n",
    "    estimator=rf_model,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv=purged_cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Usa todos los núcleos del CPU para acabar rápido\n",
    "    verbose=1   # Te mostrará una barra de progreso o logs básicos\n",
    ")\n",
    "\n",
    "print(\"\\n--- Resultados de PurgedKFold ---\")\n",
    "print(f\"Scores por Fold: {scores}\")\n",
    "print(f\"Accuracy Promedio: {np.mean(scores):.2%}\")\n",
    "print(f\"Desviación Estándar: {np.std(scores):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
